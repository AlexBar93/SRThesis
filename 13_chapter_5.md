# Applicazioni

## YOLO

Le prime reti neurali per object detection erano formate da un insieme di classificatori applicati a varie scale e posizioni dell'immagine, per riconoscere vari tipi di oggetti. Altri metodi popolari usavano prima un sistema di segmentazione, per trovare nell'immagine regioni con oggetti da classificare, e poi usavano classificatori su queste regioni per determinare a quale classe appartenesse l'oggetto. Con la rete YOLO (You Only Look Once) invece l'object detection diventa un problema di regressione dai pixel dell'immagine direttamente alle coordinate dei box contenenti gli oggetti e alle probabilità delle rispettive classi. Ciò comporta due vantaggi principali: YOLO è molto veloce, tanto da poter essere eseguito in real-time anche su registrazioni live da videocamere per esempio, e inoltre commette molti meno falsi positivi sul background perchè ha uno sguardo d'insieme sull'immagine invece di dividerla in zone. Il problema principale di YOLO è la localizzazione: sebbene sia un ottimo classificatore, le posizioni dei box attorno agli oggetti non sono sempre molto precise.

### Funzionamento: estrazione delle feature e classificazione

L'immagine di input viene divisa in una griglia *S* x *S*. Se il centro di un oggetto ricade all'interno di una cella della griglia, questa sarà responsabile di rilevare quell'oggetto. Ogni cella prevede *B* box e i rispettivi punteggi di confidenza, definiti come _Pr(oggetto)_ x _IOU(previsione/realtà)_. *Pr* rappresenta la probabilità che il box contenga un oggetto, mentre _IOU_ (intersection over union) rappresenta la precisione del box rispetto all'oggetto effettivo da rilevare. Ogni box ha 5 previsioni: *x*,*y*,*w*,*h* e la confidenza. Le coordinate rappresentano il centro del box rispettivamente ai bordi della cella e le sue dimensioni rispetto all'immagine, quindi sono tutti valori compresi tra 0 e 1. Ogni cella prevede anche *C* probabilità condizionali di classe _Pr(Classe<sub>i</sub> /oggetto)_. A test time queste probabilità vengono moltiplicate per i punteggi di confidenza per ottenere punteggi specifici di classe per ogni oggetto. L'insieme di tutte le previsioni viene codificato in un tensore *S* x *S* x (*B* x *5* + *C*). Il 5 è dato dalle 4 coordinate e della confidenza.

### Modifiche delle versioni successive

La versione attuale di YOLO è la v3. Rispetto alla prima rete utilizzata la struttura del network ha subito grossi cambiamenti e nella v3 si basa sulla rete Darknet53. Alcune delle modifiche rilevanti sono:

- **Batch normalization:** Questa tecnica consiste nel normalizzare l'output di un layer scalandone e aggiustandone le attivazioni. Applicandola su tutti i layer di convoluzione del network il modello diventa molto più regolare e stabile. Ciò è vero nel caso dell'object detection, tuttavia è stato dimostrato (ref) che questa tecnica non funziona per la super-risoluzione, in quanto riduce troppo la flessibilità della rete e per ripristinare il contenuto ad alta frequenza c'è bisogno di una gamma dinamica ampia.
- **Addestramento a scala multipla:** Il network viene addestrato su immagini di dimensione variabile da 320x320 a 608x608 (andando per multipli di 32, che è il fattore di downscale della rete). Questo rende i filtri più sensibili alle informazioni dettagliate date dalla risoluzione maggiore (rispetto ai 224x224 di YOLOv1) e inoltre rende il network più robusto perchè i filtri si adattano a trovare oggetti a varie scale. Per la detection il network sarà facilmente riscalabile scegliendo le dimensioni di input offrendo un tradeoff tra precisione e velocità. Durante i test in questa tesi ho sempre utilizzato YOLOv3 con dimensioni dell'immagine di input 608x608 per avere i risultati di qualità migliore possibile.
- **Box fissi:** Per determinare i box YOLOv1 usava dei layer fully connected nel cui output si trovano direttamente le coordinate del box. Tuttavia è stato dimostrato in altre reti come la Faster R-CNN che usare dei box a dimensione fissa come priori e usare un layer di convoluzione per determinare l'offset e la confidenza dei box per la detection a partire da essi migliora le performance e rende l'addestramento più stabile. Visto che il layer è di convoluzione l'output sarà una feature map di questi offset e confidenze. Togliendo un pooling layer dalla rete per avere le dimensioni dell'output del layer di convoluzione maggiori e usando un input 608x608, avremo una feature map 19x19. Con questo cambiamento separiamo anche il meccanismo di previsione delle classi dalla posizione spaziale nell'immagine e invece calcoliamo le probabilità relative delle classi per ogni box. Avere box fissi peggiora lievemente la precisione della rete (definita come il rapporto tra i veri positivi della classificazione e la somma di veri positivi e falsi positivi) ma ne migliora notevolmente il recupero (definito come il rapporto tra i veri positivi e la somma di veri positivi e falsi negativi).
- **Cluster dimensionali:** Nella Faster R-CNN le dimensioni dei box fissi sono decise a priori e a mano. In YOLOv2 e v3 sono decise a priori ma sono state scelte dopo aver effettuato un k-mean clustering sui dataset VOC e COCO per avere un buon rapporto efficienza / precisione. Si è optato per avere 5 box fissi diversi, da cui la rete parte per trovare i box finali.
- **Previsione diretta della posizione:** Per migliorare la stabilità del network, invece di prevedere le coordinate del box fisso rispetto all'intera immagine come nella Faster R-CNN, viene usato un approcio nel quale ogni cella (della feature map) prevede 5 box e le loro coordinate relative alla cella. Ciò limita gli output tra 0 e 1 (limite imposto nel network da attivazioni logistiche), rendendo la parametrizzazione più efficace per far imparare il network.
- **Previsione a scala multipla:** Per migliorare la precisione nella detection di oggetti piccoli e/o vicini, viene preso l'output di più layer precedenti al layer di convoluzione che crea la feature map per creare una seconda e una terza feature map, di dimensioni maggiori. Queste mappe conterranno informazioni a risoluzione spaziale più ampia, e vengono concatenate alla prima dopo essere state ridimensionate a 19x19 (per fare ciò viene aumentato il numero di canali in modo da mantenere le dimensioni effettive). In YOLOv3 abbiamo quindi il contributo di 3 scale, e ogni scala prevede 3 box (quindi abbiamo in questo caso 9 box fissi a priori).
- **Classificazione a label multipla:** Visto che alcuni dataset come per esempio l'Open Image Dataset contengono classi che si possono sovrapporre (come "donna" e "persona"), per rendere YOLOv3 più versatile su questi database si introducono  indipendenti classificatori logistici in modo da prevedere per ogni box più di una label.

## Super-risoluzione e object detection

Uno dei problemi principali di YOLO, oltre alla precisione nella localizzazione, è la detection di oggetti piccoli e vicini. Per questo motivo è plausibile aspettarsi che l'utilizzo di una rete per super-risoluzione per migliorare la qualità di un'immagine prima di applicarvi la rete YOLO per object detection ne migliori i risultati e la precisione. Per verificare questa ipotesi ho effettuato due test, entrambi su immagini contententi persone. In entrambi i casi ho analizzato con YOLO quattro immagini: l'immagine di partenza di dimensioni 152x152 (che viene ridimensionata dalla rete a 608x608 linearmente prima dei calcoli), l'immagine ridimensionata bicubicamente con scala 4 di dimensioni 608x608 e le due immagini super-risolute dalle reti EDSR e WDSR, anche esse di dimensioni 608x608. Si possono notare dalle figure \ref{yolotest1} e \ref{yolotest2} alcuni dettagli:

- nel caso 1 le persone sono di dimensioni considerevoli e già nell'immagine a bassa risoluzione YOLO riesce senza problemi a trovarle tutte. Tuttavia in questo caso le probabilità di classificazione della rete sono peggiori delle immagini super-risolute, dimostrando una precisione inferiore. Inoltre alcuni oggetti piccoli (come per esempio lo zaino nella figura) vengono rilevati solo nelle immagini SR;
- nel caso 2 le persone sono di dimensioni inferiori e infatti abbiano un numero maggiore di detection nelle immagini super-risolute su persone che YOLO non riesce a trovare nell'immagine a bassa risoluzione.


far vedere come migliora sull'immagine la detection e come migliorano le probabilità

## Lavori futuri

Il miglioramento delle performance delle reti di object detection su immagini super-risolute è noto già da alcuni lavori (ref), ma non è l'unico possibile campo di applicazione della super-risoluzione. Potendo addestrare i modelli delle reti su dataset particolari come per esempio immagini di microscopia o di risonanze magnetiche, probabilmente sarebbe possibile migliorarne la qualità per scopi pratici in campo medico. Anche in questo caso sono già state svolte delle ricerche (ref super res microscopy) ma l'argomento è ancora una novità in moltissimi ambienti e quindi ha molto potenziale per essere sviluppato e molte possibili applicazioni.

Altri lavori futuri più centrati sulla libreria che sui modelli implementabili comprendono:

- Byron su tutti i sistemi operativi: Per ora Byron è stato testato esaustivamente solo su ambiente Linux ma è stato progettato per essere multi piattaforma e compatibile anche con sistemi operativi Windows e Mac. Ulteriori test sono necessari per verificare la compatibilità e l'ottimizzazione su altri sistemi e sicuramente avere una libreria che funzioni in qualsiasi ambiente è un ottimo obiettivo da raggiungere.
- Byron su GPU: Vero che l'idea alla base di Byron è l'ottimizzazione per CPU multi-core quali i server di bio-informatica, ma qualsiasi libreria per reti neurali che si rispetti deve avere anche un'implementazione su GPU di pari passo a quella CPU in modo da poter sfruttare qualsiasi hardware disponibile nel miglior modo possibile. A questo scopo sarebbe l'ideale implementare sia una versione in CUDA che una versione in OpenCL della libreria, in modo da garantirsi il funzionamento sulla maggioranza delle GPU moderne.
- Ottimizzazioni di codice: Altri possibili miglioramenti su cui sto già lavorando riguardano l'implementazione e lo sviluppo di nuovi algoritmi per ottimizzare i layer più intensivi delle reti quali per esempio layer di convoluzione e batch-normalization. Uno di essi per esempio è l'algoritmo Winograd per la convoluzione che dovrebbe garantire un notevole speedup per i layer con filtri di dimensione 3x3 che ormai sono alla base della maggior parte delle reti per elaborazione immagini.
