# Introduzione {.unnumbered}

Le reti neurali artificiali (ANN) sono modelli di calcolo informatico-matematici composti da neuroni artificiali che si ispirano al funzionamento biologico del cervello umano e basati sull'interconnessione delle informazioni.

L’idea di poter replicare artificialmente il cervello, simulandone il funzionamento attraverso delle unità di calcolo, ha una storia che inizia dai primi anni Quaranta del secolo scorso (il primo neurone artificiale fu proposto da W.S. McCulloch e W. Pitts [@neuron]). Da allora le ANN si sono sviluppate diventando un fenomeno emergente della realtà odierna ed evolvendosi nelle cosiddette Deep Neural Network (DNN). Esse consistono semplicemente in reti neurali che però hanno degli strati nascosti (comunemente chiamati hidden layer) tra il livello degli input e quello degli output della rete. Questi layer possono essere di vario tipo, a seconda delle funzioni che svolgono.

Il campo di applicazione principale delle DNN è il machine learning, ovvero l'apprendimento di informazioni dall'esperienza guidato da algoritmi matematici adattivi e automatici. In parole povere, le reti neurali possono imparare a risolvere problemi molto complessi, se strutturate e addestrate nel modo giusto. Per fare ciò ovviamente devono prima apprendere: ciò avviene nella cossidetta fase di training, che può essere di vario tipo:

- **Supervisionato**: all'algoritmo vengono forniti sia i dati in input che i dati in output attesi, in modo che la rete aggiusti i suoi parametri per avvicinarsi sempre di più ad ottenere il risulatato desiderato, imparando una o più regole o in generale funzioni molto complesse che collegano una classe di input simili a quello dato con i rispettivi output.
- **Non supervisionato**: al sistema vengono formiti solamente i dati in input, lasciando che la rete stessa trovi qualche connessione logica o schema sottostante alla struttura dei dati. In questo caso gli output della rete non sono sempre di facile interpretazione ed è anche difficile capirne la validità.
- **Semi-supervisionato**: questo è un modello ibrido in cui alcuni dati di input hanno i corrispetivi dati di output attesi mentre altri non sono etichettati. L'obiettivo è sempre quello di identificare le regole per trasformare gli input in modo da ottenere qualcosa il più simile possibile agli output. Si noti che il concetto di "similarità" dipende dalla rete e viene scelto da chi crea il suo modello. Alcuni esempi molto utilizzati sono le GANN (General Adversarial Neural Network).
- **Per rinforzo**: il sistema in questo caso interagisce con un ambiente dinamico e, una volta elaborati i dati in input, deve raggiungere un obiettivo. A seconda del risultato ottenuto verrà fornita una "ricompensa" o una "punizione", per far capire alla rete in quale direzione sta procedendo. Come anche in tutti gli altri casi, le routine di addestramento vengono ripetute moltissime volte finchè la rete non svolge le funzioni desiderate o raggiunge la saturazione di tuning dei pesi.

Ovviamente nel caso in cui la rete smetta di apprendere prima di raggiungere il suo funzionamento previsto, potrebbe essere il caso di cambiare metodo e parametri scelti durante l'addestramento oppure di rivedere la struttura della rete stessa.

Per addestrare (in modo supervisionato) una rete neurale solitamente viene usata una procedura nota come _backpropagation_. Ciò permette di partire da una funzione di errore scelta a priori che valuti quanto siano differenti l'output atteso e quello ottenuto, e propagare all'indietro nella rete questo errore, correggendo i pesi di un layer alla volta. Per fare ciò ovviamente i layer hanno bisogno di funzioni che dicano alla rete come aggiustare i pesi in base all'errore. Solitamente queste funzioni, chiamate appunto backward, sono simili alle rispettive forward utilizzate quando usiamo una rete per inferenza, ma più complesse. Infatti per aggiustare i pesi viene seguita la regola di discesa del gradiente: viene calcolata la derivata della funzione di errore rispetto ai pesi e in questo modo si calcola la funzione di errore per il layer precedente. Questo processo viene ripetuto fino a raggiungere il primo layer della rete, permettendo di aggiustare tutti i pesi per seguire appunto la direzione decrescente del gradiente per cercare di arrivare a un minimo della funzione di errore.

L'addestramento delle reti neurali esula dallo scopo di questa trattazione e quindi non approfondirò l'argomento. Tuttavia per capire il motivo per cui i layer di cui parlerò servano effettivamente alla rete, è importante parlare del problema della scomparsa del gradiente. Questo fenomeno si presenta durante l'addestramento di reti neurali con molti layer in cui l'errore viene propagato seguendo la regola della discesa del gradiente. In tale metodo, ogni parametro del modello riceve ad ogni iterazione un aggiornamento proporzionale alla derivata parziale della funzione di errore sull'output rispetto al parametro stesso. Solitamente durante il forward, dopo aver calcolato quella che è l'effettiva funzione del layer, viene applicata al risultato una funzione di attivazione (che rappresenta in biologia il _firing_ dei neuroni). Le funzioni comunemente usate nelle ANN sono la tangente iperbolica e la funzione logistica, che hanno un gradiente nell'intervallo di valori [0,1]. Ciò significa che durante la _backpropagation_ i vari gradienti che vengono moltiplicati per determinare la correzione dei parametri dei primi layer della rete, il cui numero dipende appunto da quanti layer è profonda la rete stessa, tendono a zero. Di conseguenza i layer più vicini agli input sono molto più difficili da addestrare di quelli vicini agli output e ciò può bloccare l'avanzamento dell'apprendimento della rete.

Le soluzioni più comunemente impiegate per ovviare a questo problema comprendono la sostituzione delle attivazioni lineari con attivazioni ReLU[@relu], l'utilizzo di blocchi residui [@residual] e l'addestramento con l'algoritmo di Stochastic Gradient Descent (SGD)[@sgd]. Quest'ultimo consiste praticamente nell'aggiustare i pesi della rete solo dopo aver fatto il forward di un gruppo di dati (chiamato _batch_).

In questo lavoro è proposto un nuovo framework di sviluppo di reti neurali in C++ (Byron, *Build YouR Own Neural Network*) con particolare attenzione all'implementazione di architetture a super-risoluzione ed object detection.
Il software sviluppato è interamente parallelizzato su architetture a CPU andando a massimizzarne l'efficienza di calcolo su strutture a server con elevato numero di core, solitamente impiegate in settori di ricerca finora lasciati fuori dal mondo del deep learning poichè privi di acceleratori GPU, come quello della bioinformatica e della bio-medica.
Le performance di calcolo di Byron sono state testate e confrontate con le più comuni librerie quali Darknet [@darknet], PyTorch[@pytorch] e Keras[@keras] ottenendo performance superiori nel campo dell'object detection e risultati comparabili nel campo della super-risoluzione.
